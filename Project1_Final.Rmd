---
title: "{Fill in title}"
author: "{Fill in names}"
header-includes:
- \usepackage{amsgen,amsmath,amstext,amsbsy,amsopn,amssymb,mathabx,amsthm,bm,bbm}
- \usepackage[labelsep=space]{caption}
output:
  pdf_document: default
  word_document: default
  html_document: default
subtitle: $\textbf{Machine Learning, Spring 2021}$
---

# Abstract - Matt
*{Fill in your abstract}*

# Introduction - Puyao
*{Fill in your introduction}*

# Setup
```{r, include=F, warning=F}
set.seed(315)
# Load necessary packages
library(tidyverse)
library(gridExtra)
library(ggrepel)
library(cluster)
library(factoextra)
library(class)
```


# Loading and Preprocessing the Data
1. Begin by loading the dataset you've chosen. Depending on which dataset you've chosen, it may be helpful to consider a subset of the data for your analyses. Give an explanation as to why you did or did not subset your data.
```{r}
# Load the data.
DF <- read.table("TCGA_sample.txt", header = T) #we are going to use this dataset
```

2. Next, provide some basic information about the data. What are the samples and what are the variables? How many samples are there? How many variables are there? How many of those variables are numerical vs categorical? How many of the numerical variables are discrete? Discuss any other information about the data that you think is relevant.

DATA:
An anonymized dataset of gene expression values from 2000 genes measured for 217 breast cancer tumors. Each tumor has been labeled according to its subtype: *Normal* or *Basal*.

All variables besides the classifier are real numeric. 

Not really much else to say about the data, very wide matrix with lots of numeric columns.
```{r}
# str(DF)
head(DF)[, 1:5]
summary(DF)[, 1:5]
```

3. In some scenarios, it may be helpful to transform or preprocess your data in some way before embarking on your analysis. For example, one may wish to center and standardize each numerical variable before performing certain regression analyses. On the other hand, one may wish to group some factors of a categorical variable together. Perform any preprocessing that you feel is appropriate and discuss the motivation for this choice. If you decide not to, explain why. Note that it may be helpful to omit this step and return at a later point once you have explored the data a bit.

We want to center and standardize all the numerical columns. This should be the only task we really need to do. We want to center and scale them becasue I am not sure exactly how these measurements are found so some of them might not be on the same scale as others. Centering and scaling rarely has a negative impact on the analyisis since this process keeps the structure of the data intact. 

```{r}
DF.Center <- data.frame(
  "Subtype" = DF$Subtype
)
DF.Center <- cbind(DF.Center, scale(DF[, -1], scale = T, center = T))
```

# Exploratory Data Analysis
4. Provide a statistical summary of the data as well as a summary of the data in words. Note that it is not necessary to list every summary statistic for every variable. Rather, try to give the reader a sense of what kinds of values the variables take on. And don't forget any categorical variables!

The data is 217 tumors with 2000 gene samples each. The tumors are all labeled as Basal or Normal. The gene samples are numeric real numbers. 
```{r}
summary(DF.Center)[, 1:5]
str(DF.Center, list.len = 5)
```

5. Pick three variables in your dataset and visualize the distribution of each in separate plots. Remember to properly title and label each plot. Compare them and comment on what you see. Do any of the distributions appear similar or different? In what ways?
```{r}
g1 <- DF.Center %>% 
  ggplot(aes(x=Gene.1)) +
  geom_density(col = "Blue") +
  theme_minimal() +
  labs(title = "Density of Gene 1", 
       y = "Density", 
       x = "Gene 1")

g2 <- DF.Center %>% 
  ggplot(aes(x=Gene.100)) +
  geom_density(col = "Red") +
  theme_minimal() +
  labs(title = "Density of Gene 100", 
       y = "Density", 
       x = "Gene 100")

g3 <- DF.Center %>% 
  ggplot(aes(x=Gene.1000)) +
  geom_density(col = "Green") +
  theme_minimal() +
  labs(title = "Density of Gene 1000", 
       y = "Density", 
       x = "Gene 1000")

grid.arrange(g1, g2, g3)
```

Here we have plotted the density of Gene 1, 100, and 1000. Gene 1 and Gene 1000 seem to have an almost normal distribution. Gene 1000 is a bit more spread out but still looks almost normal around 0 (remember this is centered data). Gene 100 seems to be left skewed so it is a bit different than the other two genes. 

6. Pick two numerical variables in your dataset. What is their correlation? Visualize their joint behavior in a single plot. Does this suggest that there is a strong relationship between the two?
```{r}
# Compute correlation.
attach(DF.Center)
cor(Gene.2, Gene.200)
# Plot joint behavior.
DF.Center %>% 
  ggplot(aes(x=Gene.2, y=Gene.200)) +
  geom_point(col = "black") +
  theme_minimal() 
```

This plot shows that there is not much of a relationship between these two columns. 

7. Pick two numerical variables in your dataset. Perform a hypothesis test to check whether their means are equal. Discuss what test you performed and why. What is the result of the test? Note that such a test won't make sense if you have centered your data so you should apply this to your data without any centering.
```{r}
# Perform hypothesis test.
var(DF$Gene.2)
var(DF$Gene.200)

Hypo.dat <- data.frame("Gene 2" = DF$Gene.2, 
                       "Gene 200" = DF$Gene.200)
Hypo.dat %>% 
  pivot_longer(c(1, 2), names_to = "Gene", values_to = "Value") %>% 
  ggplot(aes(x=Gene, y=Value)) +
  geom_violin(aes(col = Gene)) +
  stat_summary(fun=mean, geom="point", shape=20, size=5, color="red", fill="red") +
  theme_minimal()

#variances are slightly different
t.test(DF$Gene.2, DF$Gene.200, var.equal = F)
```

We first check the variance of each column we are doing the hypothesis test for. In this case, we find the variances are different so we should use the Welch Two Sample t-test. From this t-test we find a p-value of .1. This means we cannot reject the null hypothesis that the means are the same at $\alpha$ = .05, thus we are unsure if the difference in means is 0 or not. If we look at the boxplots we can see that the means are very close to one another.

8. In a single plot, visualize the relationship between the means or medians and the standard deviations of each variable. Do you notice any outliers? 
```{r}
# Plot means or medians vs sds.
#using original DF not Centered DF
Means <- rowMeans(DF[,-1])
SDs <- apply(DF[,-1], 1, sd)

M.SD <- data.frame(
  "Mean" = Means, 
  "SD" = SDs
)

M.SD %>% 
  ggplot(aes(x=Mean, y=SD)) +
  geom_point(fill = "Purple", alpha = .75, col = "black", pch = 21) +
  labs(title = "Mean vs. Standard Deviation") +
  geom_text_repel(data = M.SD %>% filter(SD>1.9), aes(label = "Potential Outlier"), hjust = -.5) +
  theme_minimal()
```

There is one potential outlier on the plot. It seems to have a much higher SD than expected in a linear trend like this. 

# Principal Components Analysis - Henry Cervantes
9. Next, we would like to reduce the dimension of the data. Explain what the "dimension" of a dataset is. Discuss why one would want to reduce it. Provide an intuitive explanation of how PCA can achieve this.

The data contains 217 observations of 2000 variables not including the response, this is the dimension of the data. Naturally this is a very large dataset and cumbersome to work with. The idea behind PCA is to reduce the dimension by projecting the data onto a smaller dimension while trying to retain as much of the variability from the original dataset as possible. This way we could have less variables that contain the most important information from the original dataset.

10. Run PCA on the dataset. Decide whether to set *scale = TRUE* or *scale = FALSE* and explain your choice. Provide a numerical summary of the first 5 PCs. Note that you should leave any categorical variables out of this analysis.

Since we are already using scaled data, I'm going to leave *scale = FALSE*. The reason for using scaled data is that not all variances are equal across columns. This difference in variance could cause PCA to assign more weight to genes with the highest variance. While it might be advisable to give more weight to certain genes, we're not sure which ones deserve the greater weight. For that reason we will treat all genes as equal. 
```{r}
# for (i in 2:10){
#   print(sd(DF[,i]))
# }
```

```{r}
PCA <- prcomp(DF.Center[,-1])

summary(PCA$x[,1:5])
```

11. Plot a screeplot of the PCs. How many principal components are required to explain at least 80% of the variation in the data? Based on this and the plot, does it seem like PCA has done a good job in reducing the dimensionality of the data?
```{r}
screeplot(PCA, type = "line", npcs = 60)

pcaCharts <- function(x) {
    x.var <- x$sdev ^ 2
    x.pvar <- x.var/sum(x.var)
    plot(cumsum(x.pvar), 
         xlab="Principal component", 
         ylab="Cumulative Proportion of Variance Explained", 
         ylim=c(0,1),
         type='b')
    abline(h = .8, col = "blue")
    abline(v = 58, col = "blue")
}

pcaCharts(PCA)
```

Since there are so many principle components it would be easier to look at a summary of the first 60 in order to find out how many are required to explain 80% of the variation in the data. 

```{r}
PCA60 <- prcomp(DF.Center[,-1], rank = 60)
summary(PCA60)
```

We need 58 principle components to explain at least 80% of the variation in the data. Considering there are 2000 variables, PCA does do a good job in reducing the dimensionality of the data. 

12. Visualize the distributions of the first 3 PCs in separate plots and comment. Are there any apparent clusters? Do any of the first 3 PCs appear most helpful for separating the data?
```{r}
Subtype <- factor(DF.Center[,1])

par(mfrow = c(3,1))

for(i in 1:3){
  plot(PCA$x[,i], 
      main = paste("PC", eval(i)), 
      xlab = "Sample Index",
      ylab = paste("PC", eval(i), "score"), 
      col = Subtype)
}

barplot(table(Subtype), col = unique(Subtype))
```

The first principle component appears to be the most helpful in separating the data. Most of the observations with a score less than 0 are basal tumors and the ones with scores greater than 0 are mostly normal. 

13. Plot the first 3 PCs against one another (see the Biplots section of Computing Assignment 3). Are there any apparent clusters?
```{r}
# biplot(PCA)
```

```{r}
pairs(PCA$x[,1:3], col = Subtype)
```

We see clusters in all plots with PC1, although PC1 vs PC2 appears to have more distinct clusters.  

# Clustering - Matt
14. Next we would like to perform a cluster analysis on the data. Explain intuitively what that means. What exactly is a cluster? What are the objects being clustered? Why might this be helpful for this dataset?

A cluster analysis is an unsupervised method of machine learning. Unsupervised means there is no indication of what is right and what is wrong, the algorithm simply tries to find some sort of structure or pattern in unlabeled data. We are hoping to find groups of observations that are similar to observations within the group, but different to others outside the group. Clusters are disjoiint groups of observations containing the observations that are "similar". Clusters that are close together are more similar then clusters that are far apart. In this case, we are attempting to cluster tumors together. When two tumors are in the same cluster, this means they are similar. Similarity is defined as the distance (Euclidean, Manhattan, Correlation, etc.) between the vectors that define each tumor, i.e. the measurements of the 2000 genes. When the distance between two of the vectors defining the tumors is small, these tumors are considered to be similar. This could be helpful in this dataset if we were given new unlabeled points and wanted to classify them. We could simply add the new observation and see what cluster it is a part of. 

15. Apply one of the clustering algorithms you learned about in class to your data. Depending on the algorithm you use, you may need to specify a cutpoint to obtain a single cluster label for each sample. Note also that depending on the dimension of your dataset, it may be preferable to apply the clustering algorithm to the first few PCs of your data rather than the data itself. Elaborate upon your choice.
```{r, warning = F, message = F}
# Apply the clustering algorithm.
# We want to cluster the scaled data so we will use DF.Center

#Lets try K-Means first. 

# Determine number of clusters
wss <- function(k) {
  kmeans(DF.Center[, -1], k, nstart = 10)$tot.withinss
}

k.values <- 1:10

wss_values <- map_dbl(k.values, wss)

plot(k.values, wss_values,
       type="b", pch = 19, frame = FALSE, 
       xlab="Number of clusters K",
       ylab="Total within-clusters sum of squares")
#seems like 2 might be a good option

fviz_nbclust(DF.Center[, -1], kmeans, method = "wss")
#confirms two is probably good
fviz_nbclust(DF.Center[, -1], kmeans, method = "silhouette")
#and a third one just to make sure

# Proceed with kmeans 2 clusters

k2 <- kmeans(DF.Center[, -1], centers = 2, nstart = 10)

fviz_cluster(k2, data = DF.Center[, -1], geom = "point") +
  geom_point(aes(shape = DF.Center$Subtype), alpha = .7) +
  theme_minimal() +
  guides(col = F) +
  guides(fill = F) +
  scale_shape_discrete(name = "Cluster", breaks = c("Basal", "Normal")) 

#Let's try one quick hierarchichal 
res.hc <- eclust(DF.Center[, -1], "hclust", nboot = 5)
fviz_dend(res.hc, rect = TRUE) 
#I think it is fairly safe to say there are two clusters
```

Since the data is very high-dimensional we decided to use the first 2 PCs to take a look at the results from the clustering algorithm. 

16. What did the clustering algorithm find? Are the clusters relatively homogeneous or heterogeneous? Summarize the results.

After a couple tests we found that the optimal number of clusters is 2. This is shown by the three line plots with a kink at 2 clusters on the x-axis. We used two different methods for finding this: the within-cluster sum of squares and a silhouette. The silhouette method looks at how close a point in one cluster is to the points in the other cluster. After knowing there were supposedly two main clusters, we continued with a k-means algorithm for clustering. This clustering found two distinct clusters that are fairly homogeneous. Since there are many overlapping points labeling become cubersome, so we instead used two different shapes for the types of tumors. From the plot above, the red cluster (cluster 1) seems to be more homoegenous containing only Normal tumors. The blue cluster (cluster 2) seemed to be mostly Basal tumors, but a few Normal tumors slipped in around the border line of the clusters. All in all, the clustering was successful and we found 2 clusters that contain similar tumors. We also completed a hierarchichal clustering to compare to the k-means algorithm. The dendrogram of that algorithm is also shown above. Clearly, there are two main groups with many much smaller subgroups. 

17. What is the within-cluster sum of squares for the clusters you found? How does this compare to the total sum of squares?
```{r}
# Compute sums of squares.
k2$withinss
k2$totss
```

The within-cluster sum of squares for both clusters was far less then the total sum of squares. This is what we are hoping for since it essentially means the points inside clusters are similar and those outside of clusters are different.

18. Plot the first 3 PCs against one another again but include the cluster label for each point. Do any patterns emerge? Comment on what you see.
```{r}
pairs(PCA$x[,1:3], col = k2$cluster)
```

This plot looks very similar to the plot in the PCA section. Again, this is what we were hoping for. A few patterns emerge from using this coloring. PC1 seems to do the best job of distinguishing between the 2 groups of tumors. When PC1 is plotted against PC2 or PC3 there are 2 clear groups of points.

# Classification
19. Next we would like to perform classification on the data. Explain intuitively what that means. What does it mean to classify the data? What are the objects being classified? Why might this be of interest for this dataset?

In many situations, the response variable is categorical. The process of *classification* is an approach for predicting categorical responses. Predicting a categorical response for an observation is referred to as *classifying* that observation, which involves assigning the observation to a category. For this dataset, the objects being classified are gene expression values from 2000 genes measured for breast cancer tumors. This is of interest because, if we have future observations of gene expression values, we will hope to predict the type of tumors.

20. Identify a categorical variable in the data to correspond to the class of each sample in the dataset. In particular, is there a variable that might be interesting to predict from the other variables?

The categorical variable in the data we will use to correspond to the class is *Subtype*. There are two classes: *Basal* and *Normal*, and we are interested in predicting *Subtype* from other variables (gene expression values from 2000 genes).

21. Construct a table that describes how many samples in each class fall into each cluster. How well was your previous cluster analysis able to identify the classes you chose? Are any of the clusters comprised mostly by one class?
```{r}
# Construct table.
# Cluster 1 is RED
# Cluster 2 is BLUE
table(DF.Center$Subtype,k2$cluster)
```
In the class of *Basal*, all 122 samples fall into the cluster 2. In the class of *Normal*, 89 samples fall into the cluster 1 and 6 samples fall into the cluster 2. Then the previous cluster analysis works well to identify the classes. Cluster 1 is mostly comprised by class 1, and cluster 2 is mostly comprised by class 2.

22. Randomly break your dataset into a training set (roughly 80% of the data) and a test set (roughly 20% of the data). What is the point of doing this before doing classification?
```{r}
# Break into train and test sets.
#Sample the rows for the training set
index <-sample(1:nrow(DF.Center),round(nrow(DF.Center)*0.8)) 
DF_train<-DF.Center[index,-1] #Training set
train_class<-as.factor(DF.Center[index,1]) #classifications of training set
DF_test<-DF.Center[-index,-1] #Test set
test_class<-as.factor(DF.Center[-index,1]) #Classifications of test set
```

We do this before doing classification since we will use the training set to construct our prediction rule, and calculate the accuracy of the fitted model on the testing set to evaluate our classifier.

23. Using the class labels based on the categorical variable you chose earlier, apply a classification method to the training set. Be sure to specify any free parameters that were chosen. What is the accuracy of the fitted model on the training set?
```{r}
# Run classification algorithm.
CL_train=knn(DF_train, DF_train, train_class, k=3)
# Compute training set accuracy.
length(which(CL_train==train_class))/length(CL_train)
```
We use the $k$-nearest neighbor rule and let $k=3$. The accuracy of the fitted model on the training set is 0.99.

24. What is the accuracy of the fitted model on the test set? How does this compare to the accuracy on the training set? Does this make sense? Explain why or why not.
```{r}
# Compute accuracy on test set.
CL_test=knn(DF_train, DF_test, train_class, k=3)
length(which(CL_test==test_class))/length(CL_test)
```
The accuracy of the fitted model on the test set is .95, which means we have made good predictions. This is slightly worse than the accuracy of the model on the train set, but this is perfectly normal since we fitted the model on the train data originally. This classifcation rule is very good at 95% accuracy on out of sample test data. This makes sense, since the data has very good structure to begin with.

25. Construct a confusion matrix based on the results of classification. Were there any classes on which your algorithm performed better than others? What about worse than others? Does this make sense based on the nature of the data?
```{r}
# Find classes where the algorithm performed best / worst.
as.matrix(table(Actual =test_class, Predicted = CL_test))
```
The algorithm performs well for both classes. This makes sense, since the data has very good structure and these two types of tumors truly are quite different. 


# Conclusion - Henry
*{Fill in your conclusion}*

